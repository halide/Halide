#ifndef included_schedule_file_SCHEDULE_H
#define included_schedule_file_SCHEDULE_H

// MACHINE GENERATED -- DO NOT EDIT
// This schedule was automatically generated by Anderson2021
// with autoscheduler_params=autoscheduler=Anderson2021 autoscheduler.active_block_limit=32 autoscheduler.active_warp_limit=64 autoscheduler.beam_size=32 autoscheduler.freeze_inline_compute_root=1 autoscheduler.parallelism=80 autoscheduler.random_dropout=100 autoscheduler.random_dropout_seed=32587330000 autoscheduler.randomize_tilings=1 autoscheduler.search_space_options=1111 autoscheduler.shared_memory_limit_kb=48 autoscheduler.shared_memory_sm_limit_kb=96

#include "Halide.h"

inline void apply_schedule_included_schedule_file(
    ::Halide::Pipeline pipeline,
    ::Halide::Target target) {
    using ::Halide::Func;
    using ::Halide::MemoryType;
    using ::Halide::RVar;
    using ::Halide::TailStrategy;
    using ::Halide::Var;

    Func relu = pipeline.get_func(4);
    Func conv = pipeline.get_func(3);
    Var c(relu.get_schedule().dims()[0].var);
    Var ci("ci");
    Var n(relu.get_schedule().dims()[3].var);
    Var x(relu.get_schedule().dims()[1].var);
    Var xi("xi");
    Var xii("xii");
    Var y(relu.get_schedule().dims()[2].var);
    Var yi("yi");
    Var yii("yii");
    RVar r13_x(conv.update(0).get_schedule().dims()[0].var);
    RVar r13_y(conv.update(0).get_schedule().dims()[1].var);
    RVar r13_z(conv.update(0).get_schedule().dims()[2].var);
    Var yi_serial_outer("yi_serial_outer");
    Var xi_serial_outer("xi_serial_outer");
    Var ci_serial_outer("ci_serial_outer");
    relu
        .split(c, c, ci, 24, TailStrategy::ShiftInwards)
        .split(x, x, xi, 16, TailStrategy::ShiftInwards)
        .split(y, y, yi, 4, TailStrategy::ShiftInwards)
        .split(xi, xi, xii, 4, TailStrategy::ShiftInwards)
        .split(yi, yi, yii, 2, TailStrategy::ShiftInwards)
        .unroll(xii)
        .unroll(yii)
        .compute_root()
        .reorder(xii, yii, ci, xi, yi, c, x, y, n)
        .gpu_blocks(c)
        .gpu_blocks(x)
        .fuse(y, n, y)
        .gpu_blocks(y)
        .split(ci, ci_serial_outer, ci, 24, TailStrategy::GuardWithIf)
        .gpu_threads(ci)
        .split(xi, xi_serial_outer, xi, 4, TailStrategy::GuardWithIf)
        .gpu_threads(xi)
        .split(yi, yi_serial_outer, yi, 2, TailStrategy::GuardWithIf)
        .gpu_threads(yi);
    conv.update(0)
        .split(c, c, ci, 24, TailStrategy::GuardWithIf)
        .split(x, x, xi, 4, TailStrategy::GuardWithIf)
        .split(y, y, yi, 16, TailStrategy::GuardWithIf)
        .split(yi, yi, yii, 2, TailStrategy::GuardWithIf)
        .unroll(yii)
        .reorder(yii, r13_x, r13_y, r13_z, ci, xi, yi, c, x, y, n)
        .gpu_blocks(c)
        .gpu_blocks(x)
        .fuse(y, n, y)
        .gpu_blocks(y)
        .split(ci, ci_serial_outer, ci, 24, TailStrategy::GuardWithIf)
        .gpu_threads(ci)
        .split(xi, xi_serial_outer, xi, 4, TailStrategy::GuardWithIf)
        .gpu_threads(xi)
        .split(yi, yi_serial_outer, yi, 8, TailStrategy::GuardWithIf)
        .gpu_threads(yi);
    conv
        .split(c, c, ci, 24, TailStrategy::ShiftInwards)
        .split(x, x, xi, 4, TailStrategy::ShiftInwards)
        .split(y, y, yi, 16, TailStrategy::ShiftInwards)
        .split(yi, yi, yii, 2, TailStrategy::ShiftInwards)
        .unroll(yii)
        .compute_root()
        .reorder(yii, ci, xi, yi, c, x, y, n)
        .gpu_blocks(c)
        .gpu_blocks(x)
        .fuse(y, n, y)
        .gpu_blocks(y)
        .split(ci, ci_serial_outer, ci, 24, TailStrategy::GuardWithIf)
        .gpu_threads(ci)
        .split(xi, xi_serial_outer, xi, 4, TailStrategy::GuardWithIf)
        .gpu_threads(xi)
        .split(yi, yi_serial_outer, yi, 8, TailStrategy::GuardWithIf)
        .gpu_threads(yi);
    conv.in(relu).store_in(MemoryType::Register).compute_at(relu, ci).bound_extent(c, 1).unroll(c).bound_extent(x, 4).unroll(x).bound_extent(y, 2).unroll(y).bound_extent(n, 1).unroll(n);
}

#endif  // included_schedule_file_SCHEDULE_H
