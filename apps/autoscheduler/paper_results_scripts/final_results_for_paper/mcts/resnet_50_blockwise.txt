
make: Entering directory '/home/ubuntu/llvm-project/Halide/apps/resnet_50_blockwise'
python3 load_weights.py bin/pytorch_weights
Traceback (most recent call last):
  File "load_weights.py", line 2, in <module>
    import torch.utils.model_zoo as model_zoo
ModuleNotFoundError: No module named 'torch'
Makefile:28: recipe for target 'bin/pytorch_weights/ok' failed
make: *** [bin/pytorch_weights/ok] Error 1
make: Leaving directory '/home/ubuntu/llvm-project/Halide/apps/resnet_50_blockwise'


RL_END_OF_RUN 1

make: Entering directory '/home/ubuntu/llvm-project/Halide/apps/resnet_50_blockwise'
python3 load_weights.py bin/pytorch_weights
Traceback (most recent call last):
  File "load_weights.py", line 2, in <module>
    import torch.utils.model_zoo as model_zoo
ModuleNotFoundError: No module named 'torch'
Makefile:28: recipe for target 'bin/pytorch_weights/ok' failed
make: *** [bin/pytorch_weights/ok] Error 1
make: Leaving directory '/home/ubuntu/llvm-project/Halide/apps/resnet_50_blockwise'


RL_END_OF_RUN 2

make: Entering directory '/home/ubuntu/llvm-project/Halide/apps/resnet_50_blockwise'
HL_PERMIT_FAILED_UNROLL=1 HL_WEIGHTS_DIR=/home/ubuntu/llvm-project/Halide/apps/autoscheduler/paper_results_scripts/../baseline.weights \
bin/resnet50block.generator -g resnet50block -o bin -f resnet50block_auto_schedule14 target=host auto_schedule=true block_id=14 -p bin/libauto_schedule.so -s Adams2019
generate_rl_schedule for target=x86-64-linux-avx-avx2-avx512-avx512_skylake-f16c-fma-sse41
Seed = 3
mcts_depth 52
num_random_trees 15
num_greedy_trees 1
best intermediate value -1.11111e+11
finished depth 0 best value so far 0
Cost evaluated this many times: 0
best intermediate value -3.00066
finished depth 1 best value so far -3.00066
Cost evaluated this many times: 334557
best intermediate value -1.11111e+11
finished depth 2 best value so far -3.00066
Cost evaluated this many times: 334557
best intermediate value -2.78909
finished depth 3 best value so far -2.78909
Cost evaluated this many times: 667853
best intermediate value -1.11111e+11
finished depth 4 best value so far -2.78909
Cost evaluated this many times: 667853
best intermediate value -1.11111e+11
finished depth 5 best value so far -2.78909
Cost evaluated this many times: 667853
best intermediate value -2.72507
finished depth 6 best value so far -2.72507
Cost evaluated this many times: 1017115
best intermediate value -1.11111e+11
finished depth 7 best value so far -2.72507
Cost evaluated this many times: 1017115
best intermediate value -2.85324
finished depth 8 best value so far -2.72507
Cost evaluated this many times: 1380167
best intermediate value -1.11111e+11
finished depth 9 best value so far -2.72507
Cost evaluated this many times: 1380167
best intermediate value -2.94604
finished depth 10 best value so far -2.72507
Cost evaluated this many times: 1712857
best intermediate value -1.11111e+11
finished depth 11 best value so far -2.72507
Cost evaluated this many times: 1712857
best intermediate value -1.11111e+11
finished depth 12 best value so far -2.72507
Cost evaluated this many times: 1712857
best intermediate value -1.11111e+11
finished depth 13 best value so far -2.72507
Cost evaluated this many times: 1712857
best intermediate value -2.41176
finished depth 14 best value so far -2.41176
Cost evaluated this many times: 2020443
best intermediate value -1.11111e+11
finished depth 15 best value so far -2.41176
Cost evaluated this many times: 2020443
best intermediate value -1.11111e+11
finished depth 16 best value so far -2.41176
Cost evaluated this many times: 2020443
best intermediate value -2.38007
finished depth 17 best value so far -2.38007
Cost evaluated this many times: 2328240
best intermediate value -2.58542
finished depth 18 best value so far -2.38007
Cost evaluated this many times: 2681322
best intermediate value -1.11111e+11
finished depth 19 best value so far -2.38007
Cost evaluated this many times: 2681322
best intermediate value -2.44151
finished depth 20 best value so far -2.38007
Cost evaluated this many times: 3015969
best intermediate value -1.11111e+11
finished depth 21 best value so far -2.38007
Cost evaluated this many times: 3015969
best intermediate value -2.45101
finished depth 22 best value so far -2.38007
Cost evaluated this many times: 3348791
best intermediate value -1.11111e+11
finished depth 23 best value so far -2.38007
Cost evaluated this many times: 3348791
best intermediate value -2.27644
finished depth 24 best value so far -2.27644
Cost evaluated this many times: 3625874
best intermediate value -1.11111e+11
finished depth 25 best value so far -2.27644
Cost evaluated this many times: 3625874
best intermediate value -1.11111e+11
finished depth 26 best value so far -2.27644
Cost evaluated this many times: 3625874
best intermediate value -2.27665
finished depth 27 best value so far -2.27644
Cost evaluated this many times: 3906286
best intermediate value -2.07852
finished depth 28 best value so far -2.07852
Cost evaluated this many times: 4231920
best intermediate value -1.11111e+11
finished depth 29 best value so far -2.07852
Cost evaluated this many times: 4231920
best intermediate value -2.01368
finished depth 30 best value so far -2.01368
Cost evaluated this many times: 4546538
best intermediate value -1.11111e+11
finished depth 31 best value so far -2.01368
Cost evaluated this many times: 4546538
best intermediate value -2.08103
finished depth 32 best value so far -2.01368
Cost evaluated this many times: 4857179
best intermediate value -1.11111e+11
finished depth 33 best value so far -2.01368
Cost evaluated this many times: 4857179
best intermediate value -2.03015
finished depth 34 best value so far -2.01368
Cost evaluated this many times: 5169266
best intermediate value -1.11111e+11
finished depth 35 best value so far -2.01368
Cost evaluated this many times: 5169266
best intermediate value -1.91202
finished depth 36 best value so far -1.91202
Cost evaluated this many times: 5503185
best intermediate value -1.11111e+11
finished depth 37 best value so far -1.91202
Cost evaluated this many times: 5503185
best intermediate value -1.11111e+11
finished depth 38 best value so far -1.91202
Cost evaluated this many times: 5503185
best intermediate value -1.11111e+11
finished depth 39 best value so far -1.91202
Cost evaluated this many times: 5503185
best intermediate value -1.90651
finished depth 40 best value so far -1.90651
Cost evaluated this many times: 5719559
best intermediate value -1.11111e+11
finished depth 41 best value so far -1.90651
Cost evaluated this many times: 5719559
best intermediate value -1.11111e+11
finished depth 42 best value so far -1.90651
Cost evaluated this many times: 5719559
best intermediate value -1.11111e+11
finished depth 43 best value so far -1.90651
Cost evaluated this many times: 5719559
best intermediate value -1.11111e+11
finished depth 44 best value so far -1.90651
Cost evaluated this many times: 5719559
best intermediate value -1.89744
finished depth 45 best value so far -1.89744
Cost evaluated this many times: 5825544
best intermediate value -1.89744
finished depth 46 best value so far -1.89744
Cost evaluated this many times: 5981045
best intermediate value -1.11111e+11
finished depth 47 best value so far -1.89744
Cost evaluated this many times: 5981045
best intermediate value -1.89744
finished depth 48 best value so far -1.89744
Cost evaluated this many times: 6345010
best intermediate value -1.11111e+11
finished depth 49 best value so far -1.89744
Cost evaluated this many times: 6345010
best intermediate value -1.11111e+11
finished depth 50 best value so far -1.89744
Cost evaluated this many times: 6345010
global best cost: 1.89744
JENNY_MINCOST: 1.89744
JENNY_EVALTIME: 6345010
num_best_decisions: 5num_random_decisions: 16
Cost evaluated this many times: 6345010
HL_PERMIT_FAILED_UNROLL=1 HL_WEIGHTS_DIR=/home/ubuntu/llvm-project/Halide/apps/autoscheduler/paper_results_scripts/../baseline.weights \
bin/resnet50block.generator -g resnet50block -o bin -f resnet50block_auto_schedule15 target=host auto_schedule=true block_id=15 -p bin/libauto_schedule.so -s Adams2019
generate_rl_schedule for target=x86-64-linux-avx-avx2-avx512-avx512_skylake-f16c-fma-sse41
Seed = 3
mcts_depth 64
num_random_trees 15
num_greedy_trees 1
best intermediate value -1.11111e+11
finished depth 0 best value so far 0
Cost evaluated this many times: 0
best intermediate value -3.05647
finished depth 1 best value so far -3.05647
Cost evaluated this many times: 355030
best intermediate value -1.11111e+11
finished depth 2 best value so far -3.05647
Cost evaluated this many times: 355030
best intermediate value -1.11111e+11
finished depth 3 best value so far -3.05647
Cost evaluated this many times: 355030
best intermediate value -1.11111e+11
finished depth 4 best value so far -3.05647
Cost evaluated this many times: 355030
best intermediate value -3.74566
finished depth 5 best value so far -3.05647
Cost evaluated this many times: 675562
best intermediate value -3.6288
finished depth 6 best value so far -3.05647
Cost evaluated this many times: 966378
best intermediate value -3.03353
finished depth 7 best value so far -3.03353
Cost evaluated this many times: 1242237
best intermediate value -1.11111e+11
finished depth 8 best value so far -3.03353
Cost evaluated this many times: 1242237
best intermediate value -1.11111e+11
finished depth 9 best value so far -3.03353
Cost evaluated this many times: 1242237
best intermediate value -1.11111e+11
finished depth 10 best value so far -3.03353
Cost evaluated this many times: 1242237
best intermediate value -1.11111e+11
finished depth 11 best value so far -3.03353
Cost evaluated this many times: 1242237
best intermediate value -1.11111e+11
finished depth 12 best value so far -3.03353
Cost evaluated this many times: 1242237
best intermediate value -3.23799
finished depth 13 best value so far -3.03353
Cost evaluated this many times: 1510298
best intermediate value -3.42702
finished depth 14 best value so far -3.03353
Cost evaluated this many times: 1784476
best intermediate value -1.11111e+11
finished depth 15 best value so far -3.03353
Cost evaluated this many times: 1784476
best intermediate value -3.06665
finished depth 16 best value so far -3.03353
Cost evaluated this many times: 2064845
best intermediate value -1.11111e+11
finished depth 17 best value so far -3.03353
Cost evaluated this many times: 2064845
best intermediate value -3.33678
finished depth 18 best value so far -3.03353
Cost evaluated this many times: 2327382
best intermediate value -1.11111e+11
finished depth 19 best value so far -3.03353
Cost evaluated this many times: 2327382
best intermediate value -2.87803
finished depth 20 best value so far -2.87803
Cost evaluated this many times: 2607948
best intermediate value -1.11111e+11
finished depth 21 best value so far -2.87803
Cost evaluated this many times: 2607948
best intermediate value -1.11111e+11
finished depth 22 best value so far -2.87803
Cost evaluated this many times: 2607948
best intermediate value -1.11111e+11
finished depth 23 best value so far -2.87803
Cost evaluated this many times: 2607948
best intermediate value -2.87543
finished depth 24 best value so far -2.87543
Cost evaluated this many times: 2864073
best intermediate value -2.97375
finished depth 25 best value so far -2.87543
Cost evaluated this many times: 3113921
best intermediate value -2.8604
finished depth 26 best value so far -2.8604
Cost evaluated this many times: 3388653
best intermediate value -1.11111e+11
finished depth 27 best value so far -2.8604
Cost evaluated this many times: 3388653
best intermediate value -2.81293
finished depth 28 best value so far -2.81293
Cost evaluated this many times: 3673298
best intermediate value -1.11111e+11
finished depth 29 best value so far -2.81293
Cost evaluated this many times: 3673298
best intermediate value -2.71744
finished depth 30 best value so far -2.71744
Cost evaluated this many times: 3934754
best intermediate value -1.11111e+11
finished depth 31 best value so far -2.71744
Cost evaluated this many times: 3934754
best intermediate value -2.75608
finished depth 32 best value so far -2.71744
Cost evaluated this many times: 4209624
best intermediate value -1.11111e+11
finished depth 33 best value so far -2.71744
Cost evaluated this many times: 4209624
best intermediate value -2.45805
finished depth 34 best value so far -2.45805
Cost evaluated this many times: 4456002
best intermediate value -1.11111e+11
finished depth 35 best value so far -2.45805
Cost evaluated this many times: 4456002
best intermediate value -1.11111e+11
finished depth 36 best value so far -2.45805
Cost evaluated this many times: 4456002
best intermediate value -2.35938
finished depth 37 best value so far -2.35938
Cost evaluated this many times: 4711839
best intermediate value -2.20339
finished depth 38 best value so far -2.20339
Cost evaluated this many times: 4990619
best intermediate value -1.11111e+11
finished depth 39 best value so far -2.20339
Cost evaluated this many times: 4990619
best intermediate value -2.1639
finished depth 40 best value so far -2.1639
Cost evaluated this many times: 5268510
best intermediate value -1.11111e+11
finished depth 41 best value so far -2.1639
Cost evaluated this many times: 5268510
best intermediate value -2.1639
finished depth 42 best value so far -2.1639
Cost evaluated this many times: 5546920
best intermediate value -1.11111e+11
finished depth 43 best value so far -2.1639
Cost evaluated this many times: 5546920
best intermediate value -2.1639
finished depth 44 best value so far -2.1639
Cost evaluated this many times: 5824065
best intermediate value -1.11111e+11
finished depth 45 best value so far -2.1639
Cost evaluated this many times: 5824065
best intermediate value -2.1639
finished depth 46 best value so far -2.1639
Cost evaluated this many times: 6116532
best intermediate value -1.11111e+11
finished depth 47 best value so far -2.1639
Cost evaluated this many times: 6116532
best intermediate value -1.11111e+11
finished depth 48 best value so far -2.1639
Cost evaluated this many times: 6116532
best intermediate value -1.11111e+11
finished depth 49 best value so far -2.1639
Cost evaluated this many times: 6116532
best intermediate value -2.1639
finished depth 50 best value so far -2.1639
Cost evaluated this many times: 6339693
best intermediate value -1.11111e+11
finished depth 51 best value so far -2.1639
Cost evaluated this many times: 6339693
best intermediate value -1.11111e+11
finished depth 52 best value so far -2.1639
Cost evaluated this many times: 6339693
best intermediate value -1.11111e+11
finished depth 53 best value so far -2.1639
Cost evaluated this many times: 6339693
best intermediate value -1.11111e+11
finished depth 54 best value so far -2.1639
Cost evaluated this many times: 6339693
best intermediate value -2.1639
finished depth 55 best value so far -2.1639
Cost evaluated this many times: 6434012
best intermediate value -2.17329
finished depth 56 best value so far -2.1639
Cost evaluated this many times: 6517391
best intermediate value -1.11111e+11
finished depth 57 best value so far -2.1639
Cost evaluated this many times: 6517391
best intermediate value -2.17329
finished depth 58 best value so far -2.1639
Cost evaluated this many times: 6653619
best intermediate value -1.11111e+11
finished depth 59 best value so far -2.1639
Cost evaluated this many times: 6653619
best intermediate value -1.11111e+11
finished depth 60 best value so far -2.1639
Cost evaluated this many times: 6653619
best intermediate value -1.11111e+11
finished depth 61 best value so far -2.1639
Cost evaluated this many times: 6653619
best intermediate value -1.11111e+11
finished depth 62 best value so far -2.1639
Cost evaluated this many times: 6653619
global best cost: 2.1639
JENNY_MINCOST: 2.1639
JENNY_EVALTIME: 6653619
num_best_decisions: 10num_random_decisions: 16
Cost evaluated this many times: 6653619
c++ -O3 -std=c++11 -I /home/ubuntu/llvm-project/Halide/distrib/include/ -I /home/ubuntu/llvm-project/Halide/distrib/tools/  -Wall -Werror -Wno-unused-function -Wcast-qual -Wignored-qualifiers -Wno-comment -Wsign-compare -Wno-unknown-warning-option -Wno-psabi -fopenmp -g -I bin -Wall process.cpp bin/resnet50block_manual0.a bin/resnet50block_manual1.a bin/resnet50block_manual2.a bin/resnet50block_manual3.a bin/resnet50block_manual4.a bin/resnet50block_manual5.a bin/resnet50block_manual6.a bin/resnet50block_manual7.a bin/resnet50block_manual8.a bin/resnet50block_manual9.a bin/resnet50block_manual10.a bin/resnet50block_manual11.a bin/resnet50block_manual12.a bin/resnet50block_manual13.a bin/resnet50block_manual14.a bin/resnet50block_manual15.a bin/resnet50block_classic_auto_schedule0.a bin/resnet50block_classic_auto_schedule1.a bin/resnet50block_classic_auto_schedule2.a bin/resnet50block_classic_auto_schedule3.a bin/resnet50block_classic_auto_schedule4.a bin/resnet50block_classic_auto_schedule5.a bin/resnet50block_classic_auto_schedule6.a bin/resnet50block_classic_auto_schedule7.a bin/resnet50block_classic_auto_schedule8.a bin/resnet50block_classic_auto_schedule9.a bin/resnet50block_classic_auto_schedule10.a bin/resnet50block_classic_auto_schedule11.a bin/resnet50block_classic_auto_schedule12.a bin/resnet50block_classic_auto_schedule13.a bin/resnet50block_classic_auto_schedule14.a bin/resnet50block_classic_auto_schedule15.a bin/resnet50block_auto_schedule0.a bin/resnet50block_auto_schedule1.a bin/resnet50block_auto_schedule2.a bin/resnet50block_auto_schedule3.a bin/resnet50block_auto_schedule4.a bin/resnet50block_auto_schedule5.a bin/resnet50block_auto_schedule6.a bin/resnet50block_auto_schedule7.a bin/resnet50block_auto_schedule8.a bin/resnet50block_auto_schedule9.a bin/resnet50block_auto_schedule10.a bin/resnet50block_auto_schedule11.a bin/resnet50block_auto_schedule12.a bin/resnet50block_auto_schedule13.a bin/resnet50block_auto_schedule14.a bin/resnet50block_auto_schedule15.a -o bin/process  -ldl -lpthread -lz -L/home/ubuntu/anaconda3/envs/halide/lib -lpng16  -ljpeg -I/home/ubuntu/anaconda3/envs/halide/include/libpng16 -I/home/ubuntu/anaconda3/envs/halide/include/libpng16/..   
python3 load_weights.py bin/pytorch_weights
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /home/ubuntu/.cache/torch/checkpoints/resnet50-19c8e357.pth
0.0%0.0%0.0%0.0%0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%100.0%100.0%100.0%-----------loading weights------------
odict_keys(['conv1.weight', 'bn1.running_mean', 'bn1.running_var', 'bn1.weight', 'bn1.bias', 'layer1.0.conv1.weight', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.conv2.weight', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.conv3.weight', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.1.conv1.weight', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.conv2.weight', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.conv3.weight', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.2.conv1.weight', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.conv2.weight', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.conv3.weight', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer2.0.conv1.weight', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.conv2.weight', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.conv3.weight', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.1.conv1.weight', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.conv2.weight', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.conv3.weight', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.2.conv1.weight', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.conv2.weight', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.conv3.weight', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.3.conv1.weight', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.conv2.weight', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.conv3.weight', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer3.0.conv1.weight', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.conv2.weight', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.conv3.weight', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.1.conv1.weight', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.conv2.weight', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.conv3.weight', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.2.conv1.weight', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.conv2.weight', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.conv3.weight', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.3.conv1.weight', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.conv2.weight', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.conv3.weight', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.4.conv1.weight', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.conv2.weight', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.conv3.weight', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.5.conv1.weight', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.conv2.weight', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.conv3.weight', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer4.0.conv1.weight', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.conv2.weight', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.conv3.weight', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.1.conv1.weight', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.conv2.weight', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.conv3.weight', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.2.conv1.weight', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.conv2.weight', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.conv3.weight', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'fc.weight', 'fc.bias'])
weight shape before transpose
conv1.weight,(64, 3, 7, 7),4
weight shape after transpose
conv1.weight,(3, 7, 7, 64),4
weight shape before transpose
bn1.running_mean,(64,),1
weight shape after transpose
bn1.running_mean,(64,),1
weight shape before transpose
bn1.running_var,(64,),1
weight shape after transpose
bn1.running_var,(64,),1
weight shape before transpose
bn1.weight,(64,),1
weight shape after transpose
bn1.weight,(64,),1
weight shape before transpose
bn1.bias,(64,),1
weight shape after transpose
bn1.bias,(64,),1
weight shape before transpose
layer1.0.conv1.weight,(64, 64, 1, 1),4
weight shape after transpose
layer1.0.conv1.weight,(64, 1, 1, 64),4
weight shape before transpose
layer1.0.bn1.running_mean,(64,),1
weight shape after transpose
layer1.0.bn1.running_mean,(64,),1
weight shape before transpose
layer1.0.bn1.running_var,(64,),1
weight shape after transpose
layer1.0.bn1.running_var,(64,),1
weight shape before transpose
layer1.0.bn1.weight,(64,),1
weight shape after transpose
layer1.0.bn1.weight,(64,),1
weight shape before transpose
layer1.0.bn1.bias,(64,),1
weight shape after transpose
layer1.0.bn1.bias,(64,),1
weight shape before transpose
layer1.0.conv2.weight,(64, 64, 3, 3),4
weight shape after transpose
layer1.0.conv2.weight,(64, 3, 3, 64),4
weight shape before transpose
layer1.0.bn2.running_mean,(64,),1
weight shape after transpose
layer1.0.bn2.running_mean,(64,),1
weight shape before transpose
layer1.0.bn2.running_var,(64,),1
weight shape after transpose
layer1.0.bn2.running_var,(64,),1
weight shape before transpose
layer1.0.bn2.weight,(64,),1
weight shape after transpose
layer1.0.bn2.weight,(64,),1
weight shape before transpose
layer1.0.bn2.bias,(64,),1
weight shape after transpose
layer1.0.bn2.bias,(64,),1
weight shape before transpose
layer1.0.conv3.weight,(256, 64, 1, 1),4
weight shape after transpose
layer1.0.conv3.weight,(64, 1, 1, 256),4
weight shape before transpose
layer1.0.bn3.running_mean,(256,),1
weight shape after transpose
layer1.0.bn3.running_mean,(256,),1
weight shape before transpose
layer1.0.bn3.running_var,(256,),1
weight shape after transpose
layer1.0.bn3.running_var,(256,),1
weight shape before transpose
layer1.0.bn3.weight,(256,),1
weight shape after transpose
layer1.0.bn3.weight,(256,),1
weight shape before transpose
layer1.0.bn3.bias,(256,),1
weight shape after transpose
layer1.0.bn3.bias,(256,),1
weight shape before transpose
layer1.0.downsample.0.weight,(256, 64, 1, 1),4
weight shape after transpose
layer1.0.downsample.0.weight,(64, 1, 1, 256),4
weight shape before transpose
layer1.0.downsample.1.running_mean,(256,),1
weight shape after transpose
layer1.0.downsample.1.running_mean,(256,),1
weight shape before transpose
layer1.0.downsample.1.running_var,(256,),1
weight shape after transpose
layer1.0.downsample.1.running_var,(256,),1
weight shape before transpose
layer1.0.downsample.1.weight,(256,),1
weight shape after transpose
layer1.0.downsample.1.weight,(256,),1
weight shape before transpose
layer1.0.downsample.1.bias,(256,),1
weight shape after transpose
layer1.0.downsample.1.bias,(256,),1
weight shape before transpose
layer1.1.conv1.weight,(64, 256, 1, 1),4
weight shape after transpose
layer1.1.conv1.weight,(256, 1, 1, 64),4
weight shape before transpose
layer1.1.bn1.running_mean,(64,),1
weight shape after transpose
layer1.1.bn1.running_mean,(64,),1
weight shape before transpose
layer1.1.bn1.running_var,(64,),1
weight shape after transpose
layer1.1.bn1.running_var,(64,),1
weight shape before transpose
layer1.1.bn1.weight,(64,),1
weight shape after transpose
layer1.1.bn1.weight,(64,),1
weight shape before transpose
layer1.1.bn1.bias,(64,),1
weight shape after transpose
layer1.1.bn1.bias,(64,),1
weight shape before transpose
layer1.1.conv2.weight,(64, 64, 3, 3),4
weight shape after transpose
layer1.1.conv2.weight,(64, 3, 3, 64),4
weight shape before transpose
layer1.1.bn2.running_mean,(64,),1
weight shape after transpose
layer1.1.bn2.running_mean,(64,),1
weight shape before transpose
layer1.1.bn2.running_var,(64,),1
weight shape after transpose
layer1.1.bn2.running_var,(64,),1
weight shape before transpose
layer1.1.bn2.weight,(64,),1
weight shape after transpose
layer1.1.bn2.weight,(64,),1
weight shape before transpose
layer1.1.bn2.bias,(64,),1
weight shape after transpose
layer1.1.bn2.bias,(64,),1
weight shape before transpose
layer1.1.conv3.weight,(256, 64, 1, 1),4
weight shape after transpose
layer1.1.conv3.weight,(64, 1, 1, 256),4
weight shape before transpose
layer1.1.bn3.running_mean,(256,),1
weight shape after transpose
layer1.1.bn3.running_mean,(256,),1
weight shape before transpose
layer1.1.bn3.running_var,(256,),1
weight shape after transpose
layer1.1.bn3.running_var,(256,),1
weight shape before transpose
layer1.1.bn3.weight,(256,),1
weight shape after transpose
layer1.1.bn3.weight,(256,),1
weight shape before transpose
layer1.1.bn3.bias,(256,),1
weight shape after transpose
layer1.1.bn3.bias,(256,),1
weight shape before transpose
layer1.2.conv1.weight,(64, 256, 1, 1),4
weight shape after transpose
layer1.2.conv1.weight,(256, 1, 1, 64),4
weight shape before transpose
layer1.2.bn1.running_mean,(64,),1
weight shape after transpose
layer1.2.bn1.running_mean,(64,),1
weight shape before transpose
layer1.2.bn1.running_var,(64,),1
weight shape after transpose
layer1.2.bn1.running_var,(64,),1
weight shape before transpose
layer1.2.bn1.weight,(64,),1
weight shape after transpose
layer1.2.bn1.weight,(64,),1
weight shape before transpose
layer1.2.bn1.bias,(64,),1
weight shape after transpose
layer1.2.bn1.bias,(64,),1
weight shape before transpose
layer1.2.conv2.weight,(64, 64, 3, 3),4
weight shape after transpose
layer1.2.conv2.weight,(64, 3, 3, 64),4
weight shape before transpose
layer1.2.bn2.running_mean,(64,),1
weight shape after transpose
layer1.2.bn2.running_mean,(64,),1
weight shape before transpose
layer1.2.bn2.running_var,(64,),1
weight shape after transpose
layer1.2.bn2.running_var,(64,),1
weight shape before transpose
layer1.2.bn2.weight,(64,),1
weight shape after transpose
layer1.2.bn2.weight,(64,),1
weight shape before transpose
layer1.2.bn2.bias,(64,),1
weight shape after transpose
layer1.2.bn2.bias,(64,),1
weight shape before transpose
layer1.2.conv3.weight,(256, 64, 1, 1),4
weight shape after transpose
layer1.2.conv3.weight,(64, 1, 1, 256),4
weight shape before transpose
layer1.2.bn3.running_mean,(256,),1
weight shape after transpose
layer1.2.bn3.running_mean,(256,),1
weight shape before transpose
layer1.2.bn3.running_var,(256,),1
weight shape after transpose
layer1.2.bn3.running_var,(256,),1
weight shape before transpose
layer1.2.bn3.weight,(256,),1
weight shape after transpose
layer1.2.bn3.weight,(256,),1
weight shape before transpose
layer1.2.bn3.bias,(256,),1
weight shape after transpose
layer1.2.bn3.bias,(256,),1
weight shape before transpose
layer2.0.conv1.weight,(128, 256, 1, 1),4
weight shape after transpose
layer2.0.conv1.weight,(256, 1, 1, 128),4
weight shape before transpose
layer2.0.bn1.running_mean,(128,),1
weight shape after transpose
layer2.0.bn1.running_mean,(128,),1
weight shape before transpose
layer2.0.bn1.running_var,(128,),1
weight shape after transpose
layer2.0.bn1.running_var,(128,),1
weight shape before transpose
layer2.0.bn1.weight,(128,),1
weight shape after transpose
layer2.0.bn1.weight,(128,),1
weight shape before transpose
layer2.0.bn1.bias,(128,),1
weight shape after transpose
layer2.0.bn1.bias,(128,),1
weight shape before transpose
layer2.0.conv2.weight,(128, 128, 3, 3),4
weight shape after transpose
layer2.0.conv2.weight,(128, 3, 3, 128),4
weight shape before transpose
layer2.0.bn2.running_mean,(128,),1
weight shape after transpose
layer2.0.bn2.running_mean,(128,),1
weight shape before transpose
layer2.0.bn2.running_var,(128,),1
weight shape after transpose
layer2.0.bn2.running_var,(128,),1
weight shape before transpose
layer2.0.bn2.weight,(128,),1
weight shape after transpose
layer2.0.bn2.weight,(128,),1
weight shape before transpose
layer2.0.bn2.bias,(128,),1
weight shape after transpose
layer2.0.bn2.bias,(128,),1
weight shape before transpose
layer2.0.conv3.weight,(512, 128, 1, 1),4
weight shape after transpose
layer2.0.conv3.weight,(128, 1, 1, 512),4
weight shape before transpose
layer2.0.bn3.running_mean,(512,),1
weight shape after transpose
layer2.0.bn3.running_mean,(512,),1
weight shape before transpose
layer2.0.bn3.running_var,(512,),1
weight shape after transpose
layer2.0.bn3.running_var,(512,),1
weight shape before transpose
layer2.0.bn3.weight,(512,),1
weight shape after transpose
layer2.0.bn3.weight,(512,),1
weight shape before transpose
layer2.0.bn3.bias,(512,),1
weight shape after transpose
layer2.0.bn3.bias,(512,),1
weight shape before transpose
layer2.0.downsample.0.weight,(512, 256, 1, 1),4
weight shape after transpose
layer2.0.downsample.0.weight,(256, 1, 1, 512),4
weight shape before transpose
layer2.0.downsample.1.running_mean,(512,),1
weight shape after transpose
layer2.0.downsample.1.running_mean,(512,),1
weight shape before transpose
layer2.0.downsample.1.running_var,(512,),1
weight shape after transpose
layer2.0.downsample.1.running_var,(512,),1
weight shape before transpose
layer2.0.downsample.1.weight,(512,),1
weight shape after transpose
layer2.0.downsample.1.weight,(512,),1
weight shape before transpose
layer2.0.downsample.1.bias,(512,),1
weight shape after transpose
layer2.0.downsample.1.bias,(512,),1
weight shape before transpose
layer2.1.conv1.weight,(128, 512, 1, 1),4
weight shape after transpose
layer2.1.conv1.weight,(512, 1, 1, 128),4
weight shape before transpose
layer2.1.bn1.running_mean,(128,),1
weight shape after transpose
layer2.1.bn1.running_mean,(128,),1
weight shape before transpose
layer2.1.bn1.running_var,(128,),1
weight shape after transpose
layer2.1.bn1.running_var,(128,),1
weight shape before transpose
layer2.1.bn1.weight,(128,),1
weight shape after transpose
layer2.1.bn1.weight,(128,),1
weight shape before transpose
layer2.1.bn1.bias,(128,),1
weight shape after transpose
layer2.1.bn1.bias,(128,),1
weight shape before transpose
layer2.1.conv2.weight,(128, 128, 3, 3),4
weight shape after transpose
layer2.1.conv2.weight,(128, 3, 3, 128),4
weight shape before transpose
layer2.1.bn2.running_mean,(128,),1
weight shape after transpose
layer2.1.bn2.running_mean,(128,),1
weight shape before transpose
layer2.1.bn2.running_var,(128,),1
weight shape after transpose
layer2.1.bn2.running_var,(128,),1
weight shape before transpose
layer2.1.bn2.weight,(128,),1
weight shape after transpose
layer2.1.bn2.weight,(128,),1
weight shape before transpose
layer2.1.bn2.bias,(128,),1
weight shape after transpose
layer2.1.bn2.bias,(128,),1
weight shape before transpose
layer2.1.conv3.weight,(512, 128, 1, 1),4
weight shape after transpose
layer2.1.conv3.weight,(128, 1, 1, 512),4
weight shape before transpose
layer2.1.bn3.running_mean,(512,),1
weight shape after transpose
layer2.1.bn3.running_mean,(512,),1
weight shape before transpose
layer2.1.bn3.running_var,(512,),1
weight shape after transpose
layer2.1.bn3.running_var,(512,),1
weight shape before transpose
layer2.1.bn3.weight,(512,),1
weight shape after transpose
layer2.1.bn3.weight,(512,),1
weight shape before transpose
layer2.1.bn3.bias,(512,),1
weight shape after transpose
layer2.1.bn3.bias,(512,),1
weight shape before transpose
layer2.2.conv1.weight,(128, 512, 1, 1),4
weight shape after transpose
layer2.2.conv1.weight,(512, 1, 1, 128),4
weight shape before transpose
layer2.2.bn1.running_mean,(128,),1
weight shape after transpose
layer2.2.bn1.running_mean,(128,),1
weight shape before transpose
layer2.2.bn1.running_var,(128,),1
weight shape after transpose
layer2.2.bn1.running_var,(128,),1
weight shape before transpose
layer2.2.bn1.weight,(128,),1
weight shape after transpose
layer2.2.bn1.weight,(128,),1
weight shape before transpose
layer2.2.bn1.bias,(128,),1
weight shape after transpose
layer2.2.bn1.bias,(128,),1
weight shape before transpose
layer2.2.conv2.weight,(128, 128, 3, 3),4
weight shape after transpose
layer2.2.conv2.weight,(128, 3, 3, 128),4
weight shape before transpose
layer2.2.bn2.running_mean,(128,),1
weight shape after transpose
layer2.2.bn2.running_mean,(128,),1
weight shape before transpose
layer2.2.bn2.running_var,(128,),1
weight shape after transpose
layer2.2.bn2.running_var,(128,),1
weight shape before transpose
layer2.2.bn2.weight,(128,),1
weight shape after transpose
layer2.2.bn2.weight,(128,),1
weight shape before transpose
layer2.2.bn2.bias,(128,),1
weight shape after transpose
layer2.2.bn2.bias,(128,),1
weight shape before transpose
layer2.2.conv3.weight,(512, 128, 1, 1),4
weight shape after transpose
layer2.2.conv3.weight,(128, 1, 1, 512),4
weight shape before transpose
layer2.2.bn3.running_mean,(512,),1
weight shape after transpose
layer2.2.bn3.running_mean,(512,),1
weight shape before transpose
layer2.2.bn3.running_var,(512,),1
weight shape after transpose
layer2.2.bn3.running_var,(512,),1
weight shape before transpose
layer2.2.bn3.weight,(512,),1
weight shape after transpose
layer2.2.bn3.weight,(512,),1
weight shape before transpose
layer2.2.bn3.bias,(512,),1
weight shape after transpose
layer2.2.bn3.bias,(512,),1
weight shape before transpose
layer2.3.conv1.weight,(128, 512, 1, 1),4
weight shape after transpose
layer2.3.conv1.weight,(512, 1, 1, 128),4
weight shape before transpose
layer2.3.bn1.running_mean,(128,),1
weight shape after transpose
layer2.3.bn1.running_mean,(128,),1
weight shape before transpose
layer2.3.bn1.running_var,(128,),1
weight shape after transpose
layer2.3.bn1.running_var,(128,),1
weight shape before transpose
layer2.3.bn1.weight,(128,),1
weight shape after transpose
layer2.3.bn1.weight,(128,),1
weight shape before transpose
layer2.3.bn1.bias,(128,),1
weight shape after transpose
layer2.3.bn1.bias,(128,),1
weight shape before transpose
layer2.3.conv2.weight,(128, 128, 3, 3),4
weight shape after transpose
layer2.3.conv2.weight,(128, 3, 3, 128),4
weight shape before transpose
layer2.3.bn2.running_mean,(128,),1
weight shape after transpose
layer2.3.bn2.running_mean,(128,),1
weight shape before transpose
layer2.3.bn2.running_var,(128,),1
weight shape after transpose
layer2.3.bn2.running_var,(128,),1
weight shape before transpose
layer2.3.bn2.weight,(128,),1
weight shape after transpose
layer2.3.bn2.weight,(128,),1
weight shape before transpose
layer2.3.bn2.bias,(128,),1
weight shape after transpose
layer2.3.bn2.bias,(128,),1
weight shape before transpose
layer2.3.conv3.weight,(512, 128, 1, 1),4
weight shape after transpose
layer2.3.conv3.weight,(128, 1, 1, 512),4
weight shape before transpose
layer2.3.bn3.running_mean,(512,),1
weight shape after transpose
layer2.3.bn3.running_mean,(512,),1
weight shape before transpose
layer2.3.bn3.running_var,(512,),1
weight shape after transpose
layer2.3.bn3.running_var,(512,),1
weight shape before transpose
layer2.3.bn3.weight,(512,),1
weight shape after transpose
layer2.3.bn3.weight,(512,),1
weight shape before transpose
layer2.3.bn3.bias,(512,),1
weight shape after transpose
layer2.3.bn3.bias,(512,),1
weight shape before transpose
layer3.0.conv1.weight,(256, 512, 1, 1),4
weight shape after transpose
layer3.0.conv1.weight,(512, 1, 1, 256),4
weight shape before transpose
layer3.0.bn1.running_mean,(256,),1
weight shape after transpose
layer3.0.bn1.running_mean,(256,),1
weight shape before transpose
layer3.0.bn1.running_var,(256,),1
weight shape after transpose
layer3.0.bn1.running_var,(256,),1
weight shape before transpose
layer3.0.bn1.weight,(256,),1
weight shape after transpose
layer3.0.bn1.weight,(256,),1
weight shape before transpose
layer3.0.bn1.bias,(256,),1
weight shape after transpose
layer3.0.bn1.bias,(256,),1
weight shape before transpose
layer3.0.conv2.weight,(256, 256, 3, 3),4
weight shape after transpose
layer3.0.conv2.weight,(256, 3, 3, 256),4
weight shape before transpose
layer3.0.bn2.running_mean,(256,),1
weight shape after transpose
layer3.0.bn2.running_mean,(256,),1
weight shape before transpose
layer3.0.bn2.running_var,(256,),1
weight shape after transpose
layer3.0.bn2.running_var,(256,),1
weight shape before transpose
layer3.0.bn2.weight,(256,),1
weight shape after transpose
layer3.0.bn2.weight,(256,),1
weight shape before transpose
layer3.0.bn2.bias,(256,),1
weight shape after transpose
layer3.0.bn2.bias,(256,),1
weight shape before transpose
layer3.0.conv3.weight,(1024, 256, 1, 1),4
weight shape after transpose
layer3.0.conv3.weight,(256, 1, 1, 1024),4
weight shape before transpose
layer3.0.bn3.running_mean,(1024,),1
weight shape after transpose
layer3.0.bn3.running_mean,(1024,),1
weight shape before transpose
layer3.0.bn3.running_var,(1024,),1
weight shape after transpose
layer3.0.bn3.running_var,(1024,),1
weight shape before transpose
layer3.0.bn3.weight,(1024,),1
weight shape after transpose
layer3.0.bn3.weight,(1024,),1
weight shape before transpose
layer3.0.bn3.bias,(1024,),1
weight shape after transpose
layer3.0.bn3.bias,(1024,),1
weight shape before transpose
layer3.0.downsample.0.weight,(1024, 512, 1, 1),4
weight shape after transpose
layer3.0.downsample.0.weight,(512, 1, 1, 1024),4
weight shape before transpose
layer3.0.downsample.1.running_mean,(1024,),1
weight shape after transpose
layer3.0.downsample.1.running_mean,(1024,),1
weight shape before transpose
layer3.0.downsample.1.running_var,(1024,),1
weight shape after transpose
layer3.0.downsample.1.running_var,(1024,),1
weight shape before transpose
layer3.0.downsample.1.weight,(1024,),1
weight shape after transpose
layer3.0.downsample.1.weight,(1024,),1
weight shape before transpose
layer3.0.downsample.1.bias,(1024,),1
weight shape after transpose
layer3.0.downsample.1.bias,(1024,),1
weight shape before transpose
layer3.1.conv1.weight,(256, 1024, 1, 1),4
weight shape after transpose
layer3.1.conv1.weight,(1024, 1, 1, 256),4
weight shape before transpose
layer3.1.bn1.running_mean,(256,),1
weight shape after transpose
layer3.1.bn1.running_mean,(256,),1
weight shape before transpose
layer3.1.bn1.running_var,(256,),1
weight shape after transpose
layer3.1.bn1.running_var,(256,),1
weight shape before transpose
layer3.1.bn1.weight,(256,),1
weight shape after transpose
layer3.1.bn1.weight,(256,),1
weight shape before transpose
layer3.1.bn1.bias,(256,),1
weight shape after transpose
layer3.1.bn1.bias,(256,),1
weight shape before transpose
layer3.1.conv2.weight,(256, 256, 3, 3),4
weight shape after transpose
layer3.1.conv2.weight,(256, 3, 3, 256),4
weight shape before transpose
layer3.1.bn2.running_mean,(256,),1
weight shape after transpose
layer3.1.bn2.running_mean,(256,),1
weight shape before transpose
layer3.1.bn2.running_var,(256,),1
weight shape after transpose
layer3.1.bn2.running_var,(256,),1
weight shape before transpose
layer3.1.bn2.weight,(256,),1
weight shape after transpose
layer3.1.bn2.weight,(256,),1
weight shape before transpose
layer3.1.bn2.bias,(256,),1
weight shape after transpose
layer3.1.bn2.bias,(256,),1
weight shape before transpose
layer3.1.conv3.weight,(1024, 256, 1, 1),4
weight shape after transpose
layer3.1.conv3.weight,(256, 1, 1, 1024),4
weight shape before transpose
layer3.1.bn3.running_mean,(1024,),1
weight shape after transpose
layer3.1.bn3.running_mean,(1024,),1
weight shape before transpose
layer3.1.bn3.running_var,(1024,),1
weight shape after transpose
layer3.1.bn3.running_var,(1024,),1
weight shape before transpose
layer3.1.bn3.weight,(1024,),1
weight shape after transpose
layer3.1.bn3.weight,(1024,),1
weight shape before transpose
layer3.1.bn3.bias,(1024,),1
weight shape after transpose
layer3.1.bn3.bias,(1024,),1
weight shape before transpose
layer3.2.conv1.weight,(256, 1024, 1, 1),4
weight shape after transpose
layer3.2.conv1.weight,(1024, 1, 1, 256),4
weight shape before transpose
layer3.2.bn1.running_mean,(256,),1
weight shape after transpose
layer3.2.bn1.running_mean,(256,),1
weight shape before transpose
layer3.2.bn1.running_var,(256,),1
weight shape after transpose
layer3.2.bn1.running_var,(256,),1
weight shape before transpose
layer3.2.bn1.weight,(256,),1
weight shape after transpose
layer3.2.bn1.weight,(256,),1
weight shape before transpose
layer3.2.bn1.bias,(256,),1
weight shape after transpose
layer3.2.bn1.bias,(256,),1
weight shape before transpose
layer3.2.conv2.weight,(256, 256, 3, 3),4
weight shape after transpose
layer3.2.conv2.weight,(256, 3, 3, 256),4
weight shape before transpose
layer3.2.bn2.running_mean,(256,),1
weight shape after transpose
layer3.2.bn2.running_mean,(256,),1
weight shape before transpose
layer3.2.bn2.running_var,(256,),1
weight shape after transpose
layer3.2.bn2.running_var,(256,),1
weight shape before transpose
layer3.2.bn2.weight,(256,),1
weight shape after transpose
layer3.2.bn2.weight,(256,),1
weight shape before transpose
layer3.2.bn2.bias,(256,),1
weight shape after transpose
layer3.2.bn2.bias,(256,),1
weight shape before transpose
layer3.2.conv3.weight,(1024, 256, 1, 1),4
weight shape after transpose
layer3.2.conv3.weight,(256, 1, 1, 1024),4
weight shape before transpose
layer3.2.bn3.running_mean,(1024,),1
weight shape after transpose
layer3.2.bn3.running_mean,(1024,),1
weight shape before transpose
layer3.2.bn3.running_var,(1024,),1
weight shape after transpose
layer3.2.bn3.running_var,(1024,),1
weight shape before transpose
layer3.2.bn3.weight,(1024,),1
weight shape after transpose
layer3.2.bn3.weight,(1024,),1
weight shape before transpose
layer3.2.bn3.bias,(1024,),1
weight shape after transpose
layer3.2.bn3.bias,(1024,),1
weight shape before transpose
layer3.3.conv1.weight,(256, 1024, 1, 1),4
weight shape after transpose
layer3.3.conv1.weight,(1024, 1, 1, 256),4
weight shape before transpose
layer3.3.bn1.running_mean,(256,),1
weight shape after transpose
layer3.3.bn1.running_mean,(256,),1
weight shape before transpose
layer3.3.bn1.running_var,(256,),1
weight shape after transpose
layer3.3.bn1.running_var,(256,),1
weight shape before transpose
layer3.3.bn1.weight,(256,),1
weight shape after transpose
layer3.3.bn1.weight,(256,),1
weight shape before transpose
layer3.3.bn1.bias,(256,),1
weight shape after transpose
layer3.3.bn1.bias,(256,),1
weight shape before transpose
layer3.3.conv2.weight,(256, 256, 3, 3),4
weight shape after transpose
layer3.3.conv2.weight,(256, 3, 3, 256),4
weight shape before transpose
layer3.3.bn2.running_mean,(256,),1
weight shape after transpose
layer3.3.bn2.running_mean,(256,),1
weight shape before transpose
layer3.3.bn2.running_var,(256,),1
weight shape after transpose
layer3.3.bn2.running_var,(256,),1
weight shape before transpose
layer3.3.bn2.weight,(256,),1
weight shape after transpose
layer3.3.bn2.weight,(256,),1
weight shape before transpose
layer3.3.bn2.bias,(256,),1
weight shape after transpose
layer3.3.bn2.bias,(256,),1
weight shape before transpose
layer3.3.conv3.weight,(1024, 256, 1, 1),4
weight shape after transpose
layer3.3.conv3.weight,(256, 1, 1, 1024),4
weight shape before transpose
layer3.3.bn3.running_mean,(1024,),1
weight shape after transpose
layer3.3.bn3.running_mean,(1024,),1
weight shape before transpose
layer3.3.bn3.running_var,(1024,),1
weight shape after transpose
layer3.3.bn3.running_var,(1024,),1
weight shape before transpose
layer3.3.bn3.weight,(1024,),1
weight shape after transpose
layer3.3.bn3.weight,(1024,),1
weight shape before transpose
layer3.3.bn3.bias,(1024,),1
weight shape after transpose
layer3.3.bn3.bias,(1024,),1
weight shape before transpose
layer3.4.conv1.weight,(256, 1024, 1, 1),4
weight shape after transpose
layer3.4.conv1.weight,(1024, 1, 1, 256),4
weight shape before transpose
layer3.4.bn1.running_mean,(256,),1
weight shape after transpose
layer3.4.bn1.running_mean,(256,),1
weight shape before transpose
layer3.4.bn1.running_var,(256,),1
weight shape after transpose
layer3.4.bn1.running_var,(256,),1
weight shape before transpose
layer3.4.bn1.weight,(256,),1
weight shape after transpose
layer3.4.bn1.weight,(256,),1
weight shape before transpose
layer3.4.bn1.bias,(256,),1
weight shape after transpose
layer3.4.bn1.bias,(256,),1
weight shape before transpose
layer3.4.conv2.weight,(256, 256, 3, 3),4
weight shape after transpose
layer3.4.conv2.weight,(256, 3, 3, 256),4
weight shape before transpose
layer3.4.bn2.running_mean,(256,),1
weight shape after transpose
layer3.4.bn2.running_mean,(256,),1
weight shape before transpose
layer3.4.bn2.running_var,(256,),1
weight shape after transpose
layer3.4.bn2.running_var,(256,),1
weight shape before transpose
layer3.4.bn2.weight,(256,),1
weight shape after transpose
layer3.4.bn2.weight,(256,),1
weight shape before transpose
layer3.4.bn2.bias,(256,),1
weight shape after transpose
layer3.4.bn2.bias,(256,),1
weight shape before transpose
layer3.4.conv3.weight,(1024, 256, 1, 1),4
weight shape after transpose
layer3.4.conv3.weight,(256, 1, 1, 1024),4
weight shape before transpose
layer3.4.bn3.running_mean,(1024,),1
weight shape after transpose
layer3.4.bn3.running_mean,(1024,),1
weight shape before transpose
layer3.4.bn3.running_var,(1024,),1
weight shape after transpose
layer3.4.bn3.running_var,(1024,),1
weight shape before transpose
layer3.4.bn3.weight,(1024,),1
weight shape after transpose
layer3.4.bn3.weight,(1024,),1
weight shape before transpose
layer3.4.bn3.bias,(1024,),1
weight shape after transpose
layer3.4.bn3.bias,(1024,),1
weight shape before transpose
layer3.5.conv1.weight,(256, 1024, 1, 1),4
weight shape after transpose
layer3.5.conv1.weight,(1024, 1, 1, 256),4
weight shape before transpose
layer3.5.bn1.running_mean,(256,),1
weight shape after transpose
layer3.5.bn1.running_mean,(256,),1
weight shape before transpose
layer3.5.bn1.running_var,(256,),1
weight shape after transpose
layer3.5.bn1.running_var,(256,),1
weight shape before transpose
layer3.5.bn1.weight,(256,),1
weight shape after transpose
layer3.5.bn1.weight,(256,),1
weight shape before transpose
layer3.5.bn1.bias,(256,),1
weight shape after transpose
layer3.5.bn1.bias,(256,),1
weight shape before transpose
layer3.5.conv2.weight,(256, 256, 3, 3),4
weight shape after transpose

layer3.5.conv2.weight,(256, 3, 3, 256),4
weight shape before transpose
layer3.5.bn2.running_mean,(256,),1
weight shape after transpose
layer3.5.bn2.running_mean,(256,),1
weight shape before transpose
layer3.5.bn2.running_var,(256,),1
weight shape after transpose
layer3.5.bn2.running_var,(256,),1
weight shape before transpose
layer3.5.bn2.weight,(256,),1
weight shape after transpose
layer3.5.bn2.weight,(256,),1
weight shape before transpose
layer3.5.bn2.bias,(256,),1
weight shape after transpose
layer3.5.bn2.bias,(256,),1
weight shape before transpose
layer3.5.conv3.weight,(1024, 256, 1, 1),4
weight shape after transpose
layer3.5.conv3.weight,(256, 1, 1, 1024),4
weight shape before transpose
layer3.5.bn3.running_mean,(1024,),1
weight shape after transpose
layer3.5.bn3.running_mean,(1024,),1
weight shape before transpose
layer3.5.bn3.running_var,(1024,),1
weight shape after transpose
layer3.5.bn3.running_var,(1024,),1
weight shape before transpose
layer3.5.bn3.weight,(1024,),1
weight shape after transpose
layer3.5.bn3.weight,(1024,),1
weight shape before transpose
layer3.5.bn3.bias,(1024,),1
weight shape after transpose
layer3.5.bn3.bias,(1024,),1
weight shape before transpose
layer4.0.conv1.weight,(512, 1024, 1, 1),4
weight shape after transpose
layer4.0.conv1.weight,(1024, 1, 1, 512),4
weight shape before transpose
layer4.0.bn1.running_mean,(512,),1
weight shape after transpose
layer4.0.bn1.running_mean,(512,),1
weight shape before transpose
layer4.0.bn1.running_var,(512,),1
weight shape after transpose
layer4.0.bn1.running_var,(512,),1
weight shape before transpose
layer4.0.bn1.weight,(512,),1
weight shape after transpose
layer4.0.bn1.weight,(512,),1
weight shape before transpose
layer4.0.bn1.bias,(512,),1
weight shape after transpose
layer4.0.bn1.bias,(512,),1
weight shape before transpose
layer4.0.conv2.weight,(512, 512, 3, 3),4
weight shape after transpose
layer4.0.conv2.weight,(512, 3, 3, 512),4
weight shape before transpose
layer4.0.bn2.running_mean,(512,),1
weight shape after transpose
layer4.0.bn2.running_mean,(512,),1
weight shape before transpose
layer4.0.bn2.running_var,(512,),1
weight shape after transpose
layer4.0.bn2.running_var,(512,),1
weight shape before transpose
layer4.0.bn2.weight,(512,),1
weight shape after transpose
layer4.0.bn2.weight,(512,),1
weight shape before transpose
layer4.0.bn2.bias,(512,),1
weight shape after transpose
layer4.0.bn2.bias,(512,),1
weight shape before transpose
layer4.0.conv3.weight,(2048, 512, 1, 1),4
weight shape after transpose
layer4.0.conv3.weight,(512, 1, 1, 2048),4
weight shape before transpose
layer4.0.bn3.running_mean,(2048,),1
weight shape after transpose
layer4.0.bn3.running_mean,(2048,),1
weight shape before transpose
layer4.0.bn3.running_var,(2048,),1
weight shape after transpose
layer4.0.bn3.running_var,(2048,),1
weight shape before transpose
layer4.0.bn3.weight,(2048,),1
weight shape after transpose
layer4.0.bn3.weight,(2048,),1
weight shape before transpose
layer4.0.bn3.bias,(2048,),1
weight shape after transpose
layer4.0.bn3.bias,(2048,),1
weight shape before transpose
layer4.0.downsample.0.weight,(2048, 1024, 1, 1),4
weight shape after transpose
layer4.0.downsample.0.weight,(1024, 1, 1, 2048),4
weight shape before transpose
layer4.0.downsample.1.running_mean,(2048,),1
weight shape after transpose
layer4.0.downsample.1.running_mean,(2048,),1
weight shape before transpose
layer4.0.downsample.1.running_var,(2048,),1
weight shape after transpose
layer4.0.downsample.1.running_var,(2048,),1
weight shape before transpose
layer4.0.downsample.1.weight,(2048,),1
weight shape after transpose
layer4.0.downsample.1.weight,(2048,),1
weight shape before transpose
layer4.0.downsample.1.bias,(2048,),1
weight shape after transpose
layer4.0.downsample.1.bias,(2048,),1
weight shape before transpose
layer4.1.conv1.weight,(512, 2048, 1, 1),4
weight shape after transpose
layer4.1.conv1.weight,(2048, 1, 1, 512),4
weight shape before transpose
layer4.1.bn1.running_mean,(512,),1
weight shape after transpose
layer4.1.bn1.running_mean,(512,),1
weight shape before transpose
layer4.1.bn1.running_var,(512,),1
weight shape after transpose
layer4.1.bn1.running_var,(512,),1
weight shape before transpose
layer4.1.bn1.weight,(512,),1
weight shape after transpose
layer4.1.bn1.weight,(512,),1
weight shape before transpose
layer4.1.bn1.bias,(512,),1
weight shape after transpose
layer4.1.bn1.bias,(512,),1
weight shape before transpose
layer4.1.conv2.weight,(512, 512, 3, 3),4
weight shape after transpose
layer4.1.conv2.weight,(512, 3, 3, 512),4
weight shape before transpose
layer4.1.bn2.running_mean,(512,),1
weight shape after transpose
layer4.1.bn2.running_mean,(512,),1
weight shape before transpose
layer4.1.bn2.running_var,(512,),1
weight shape after transpose
layer4.1.bn2.running_var,(512,),1
weight shape before transpose
layer4.1.bn2.weight,(512,),1
weight shape after transpose
layer4.1.bn2.weight,(512,),1
weight shape before transpose
layer4.1.bn2.bias,(512,),1
weight shape after transpose
layer4.1.bn2.bias,(512,),1
weight shape before transpose
layer4.1.conv3.weight,(2048, 512, 1, 1),4
weight shape after transpose
layer4.1.conv3.weight,(512, 1, 1, 2048),4
weight shape before transpose
layer4.1.bn3.running_mean,(2048,),1
weight shape after transpose
layer4.1.bn3.running_mean,(2048,),1
weight shape before transpose
layer4.1.bn3.running_var,(2048,),1
weight shape after transpose
layer4.1.bn3.running_var,(2048,),1
weight shape before transpose
layer4.1.bn3.weight,(2048,),1
weight shape after transpose
layer4.1.bn3.weight,(2048,),1
weight shape before transpose
layer4.1.bn3.bias,(2048,),1
weight shape after transpose
layer4.1.bn3.bias,(2048,),1
weight shape before transpose
layer4.2.conv1.weight,(512, 2048, 1, 1),4
weight shape after transpose
layer4.2.conv1.weight,(2048, 1, 1, 512),4
weight shape before transpose
layer4.2.bn1.running_mean,(512,),1
weight shape after transpose
layer4.2.bn1.running_mean,(512,),1
weight shape before transpose
layer4.2.bn1.running_var,(512,),1
weight shape after transpose
layer4.2.bn1.running_var,(512,),1
weight shape before transpose
layer4.2.bn1.weight,(512,),1
weight shape after transpose
layer4.2.bn1.weight,(512,),1
weight shape before transpose
layer4.2.bn1.bias,(512,),1
weight shape after transpose
layer4.2.bn1.bias,(512,),1
weight shape before transpose
layer4.2.conv2.weight,(512, 512, 3, 3),4
weight shape after transpose
layer4.2.conv2.weight,(512, 3, 3, 512),4
weight shape before transpose
layer4.2.bn2.running_mean,(512,),1
weight shape after transpose
layer4.2.bn2.running_mean,(512,),1
weight shape before transpose
layer4.2.bn2.running_var,(512,),1
weight shape after transpose
layer4.2.bn2.running_var,(512,),1
weight shape before transpose
layer4.2.bn2.weight,(512,),1
weight shape after transpose
layer4.2.bn2.weight,(512,),1
weight shape before transpose
layer4.2.bn2.bias,(512,),1
weight shape after transpose
layer4.2.bn2.bias,(512,),1
weight shape before transpose
layer4.2.conv3.weight,(2048, 512, 1, 1),4
weight shape after transpose
layer4.2.conv3.weight,(512, 1, 1, 2048),4
weight shape before transpose
layer4.2.bn3.running_mean,(2048,),1
weight shape after transpose
layer4.2.bn3.running_mean,(2048,),1
weight shape before transpose
layer4.2.bn3.running_var,(2048,),1
weight shape after transpose
layer4.2.bn3.running_var,(2048,),1
weight shape before transpose
layer4.2.bn3.weight,(2048,),1
weight shape after transpose
layer4.2.bn3.weight,(2048,),1
weight shape before transpose
layer4.2.bn3.bias,(2048,),1
weight shape after transpose
layer4.2.bn3.bias,(2048,),1
weight shape before transpose
fc.weight,(1000, 2048),2
weight shape after transpose
fc.weight,(2048, 1000),2
weight shape before transpose
fc.bias,(1000,),1
weight shape after transpose
fc.bias,(1000,),1
echo "ok" > bin/pytorch_weights/ok
bin/process 10 auto_schedule bin/pytorch_weights cropped_panda.jpg bin/res50gen_output.bin
Loading image from cropped_panda.jpg
conv1_weight_shape.data num_dims : 4 shape: 64 7 7 3 
weight shape for bin/pytorch_weights/conv1_weight.data
64 7 7 3
bn1_running_mean_shape.data num_dims : 1 shape: 64 
bn1_running_var_shape.data num_dims : 1 shape: 64 
bn1_weight_shape.data num_dims : 1 shape: 64 
bn1_bias_shape.data num_dims : 1 shape: 64 
layer1_0_downsample_0_weight_shape.data num_dims : 4 shape: 256 1 1 64 
weight shape for bin/pytorch_weights/layer1_0_downsample_0_weight.data
256 1 1 64
layer1_0_downsample_1_running_mean_shape.data num_dims : 1 shape: 256 
layer1_0_downsample_1_running_var_shape.data num_dims : 1 shape: 256 
layer1_0_downsample_1_weight_shape.data num_dims : 1 shape: 256 
layer1_0_downsample_1_bias_shape.data num_dims : 1 shape: 256 
layer2_0_downsample_0_weight_shape.data num_dims : 4 shape: 512 1 1 256 
weight shape for bin/pytorch_weights/layer2_0_downsample_0_weight.data
512 1 1 256
layer2_0_downsample_1_running_mean_shape.data num_dims : 1 shape: 512 
layer2_0_downsample_1_running_var_shape.data num_dims : 1 shape: 512 
layer2_0_downsample_1_weight_shape.data num_dims : 1 shape: 512 
layer2_0_downsample_1_bias_shape.data num_dims : 1 shape: 512 
layer3_0_downsample_0_weight_shape.data num_dims : 4 shape: 1024 1 1 512 
weight shape for bin/pytorch_weights/layer3_0_downsample_0_weight.data
1024 1 1 512
layer3_0_downsample_1_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_0_downsample_1_running_var_shape.data num_dims : 1 shape: 1024 
layer3_0_downsample_1_weight_shape.data num_dims : 1 shape: 1024 
layer3_0_downsample_1_bias_shape.data num_dims : 1 shape: 1024 
layer4_0_downsample_0_weight_shape.data num_dims : 4 shape: 2048 1 1 1024 
weight shape for bin/pytorch_weights/layer4_0_downsample_0_weight.data
2048 1 1 1024
layer4_0_downsample_1_running_mean_shape.data num_dims : 1 shape: 2048 
layer4_0_downsample_1_running_var_shape.data num_dims : 1 shape: 2048 
layer4_0_downsample_1_weight_shape.data num_dims : 1 shape: 2048 
layer4_0_downsample_1_bias_shape.data num_dims : 1 shape: 2048 
layer1_0_conv1_weight_shape.data num_dims : 4 shape: 64 1 1 64 
weight shape for bin/pytorch_weights/layer1_0_conv1_weight.data
64 1 1 64
layer1_0_bn1_running_mean_shape.data num_dims : 1 shape: 64 
layer1_0_bn1_running_var_shape.data num_dims : 1 shape: 64 
layer1_0_bn1_weight_shape.data num_dims : 1 shape: 64 
layer1_0_bn1_bias_shape.data num_dims : 1 shape: 64 
layer1_0_conv2_weight_shape.data num_dims : 4 shape: 64 3 3 64 
weight shape for bin/pytorch_weights/layer1_0_conv2_weight.data
64 3 3 64
layer1_0_bn2_running_mean_shape.data num_dims : 1 shape: 64 
layer1_0_bn2_running_var_shape.data num_dims : 1 shape: 64 
layer1_0_bn2_weight_shape.data num_dims : 1 shape: 64 
layer1_0_bn2_bias_shape.data num_dims : 1 shape: 64 
layer1_0_conv3_weight_shape.data num_dims : 4 shape: 256 1 1 64 
weight shape for bin/pytorch_weights/layer1_0_conv3_weight.data
256 1 1 64
layer1_0_bn3_running_mean_shape.data num_dims : 1 shape: 256 
layer1_0_bn3_running_var_shape.data num_dims : 1 shape: 256 
layer1_0_bn3_weight_shape.data num_dims : 1 shape: 256 
layer1_0_bn3_bias_shape.data num_dims : 1 shape: 256 
layer1_1_conv1_weight_shape.data num_dims : 4 shape: 64 1 1 256 
weight shape for bin/pytorch_weights/layer1_1_conv1_weight.data
64 1 1 256
layer1_1_bn1_running_mean_shape.data num_dims : 1 shape: 64 
layer1_1_bn1_running_var_shape.data num_dims : 1 shape: 64 
layer1_1_bn1_weight_shape.data num_dims : 1 shape: 64 
layer1_1_bn1_bias_shape.data num_dims : 1 shape: 64 
layer1_1_conv2_weight_shape.data num_dims : 4 shape: 64 3 3 64 
weight shape for bin/pytorch_weights/layer1_1_conv2_weight.data
64 3 3 64
layer1_1_bn2_running_mean_shape.data num_dims : 1 shape: 64 
layer1_1_bn2_running_var_shape.data num_dims : 1 shape: 64 
layer1_1_bn2_weight_shape.data num_dims : 1 shape: 64 
layer1_1_bn2_bias_shape.data num_dims : 1 shape: 64 
layer1_1_conv3_weight_shape.data num_dims : 4 shape: 256 1 1 64 
weight shape for bin/pytorch_weights/layer1_1_conv3_weight.data
256 1 1 64
layer1_1_bn3_running_mean_shape.data num_dims : 1 shape: 256 
layer1_1_bn3_running_var_shape.data num_dims : 1 shape: 256 
layer1_1_bn3_weight_shape.data num_dims : 1 shape: 256 
layer1_1_bn3_bias_shape.data num_dims : 1 shape: 256 
layer1_2_conv1_weight_shape.data num_dims : 4 shape: 64 1 1 256 
weight shape for bin/pytorch_weights/layer1_2_conv1_weight.data
64 1 1 256
layer1_2_bn1_running_mean_shape.data num_dims : 1 shape: 64 
layer1_2_bn1_running_var_shape.data num_dims : 1 shape: 64 
layer1_2_bn1_weight_shape.data num_dims : 1 shape: 64 
layer1_2_bn1_bias_shape.data num_dims : 1 shape: 64 
layer1_2_conv2_weight_shape.data num_dims : 4 shape: 64 3 3 64 
weight shape for bin/pytorch_weights/layer1_2_conv2_weight.data
64 3 3 64
layer1_2_bn2_running_mean_shape.data num_dims : 1 shape: 64 
layer1_2_bn2_running_var_shape.data num_dims : 1 shape: 64 
layer1_2_bn2_weight_shape.data num_dims : 1 shape: 64 
layer1_2_bn2_bias_shape.data num_dims : 1 shape: 64 
layer1_2_conv3_weight_shape.data num_dims : 4 shape: 256 1 1 64 
weight shape for bin/pytorch_weights/layer1_2_conv3_weight.data
256 1 1 64
layer1_2_bn3_running_mean_shape.data num_dims : 1 shape: 256 
layer1_2_bn3_running_var_shape.data num_dims : 1 shape: 256 
layer1_2_bn3_weight_shape.data num_dims : 1 shape: 256 
layer1_2_bn3_bias_shape.data num_dims : 1 shape: 256 
layer2_0_conv1_weight_shape.data num_dims : 4 shape: 128 1 1 256 
weight shape for bin/pytorch_weights/layer2_0_conv1_weight.data
128 1 1 256
layer2_0_bn1_running_mean_shape.data num_dims : 1 shape: 128 
layer2_0_bn1_running_var_shape.data num_dims : 1 shape: 128 
layer2_0_bn1_weight_shape.data num_dims : 1 shape: 128 
layer2_0_bn1_bias_shape.data num_dims : 1 shape: 128 
layer2_0_conv2_weight_shape.data num_dims : 4 shape: 128 3 3 128 
weight shape for bin/pytorch_weights/layer2_0_conv2_weight.data
128 3 3 128
layer2_0_bn2_running_mean_shape.data num_dims : 1 shape: 128 
layer2_0_bn2_running_var_shape.data num_dims : 1 shape: 128 
layer2_0_bn2_weight_shape.data num_dims : 1 shape: 128 
layer2_0_bn2_bias_shape.data num_dims : 1 shape: 128 
layer2_0_conv3_weight_shape.data num_dims : 4 shape: 512 1 1 128 
weight shape for bin/pytorch_weights/layer2_0_conv3_weight.data
512 1 1 128
layer2_0_bn3_running_mean_shape.data num_dims : 1 shape: 512 
layer2_0_bn3_running_var_shape.data num_dims : 1 shape: 512 
layer2_0_bn3_weight_shape.data num_dims : 1 shape: 512 
layer2_0_bn3_bias_shape.data num_dims : 1 shape: 512 
layer2_1_conv1_weight_shape.data num_dims : 4 shape: 128 1 1 512 
weight shape for bin/pytorch_weights/layer2_1_conv1_weight.data
128 1 1 512
layer2_1_bn1_running_mean_shape.data num_dims : 1 shape: 128 
layer2_1_bn1_running_var_shape.data num_dims : 1 shape: 128 
layer2_1_bn1_weight_shape.data num_dims : 1 shape: 128 
layer2_1_bn1_bias_shape.data num_dims : 1 shape: 128 
layer2_1_conv2_weight_shape.data num_dims : 4 shape: 128 3 3 128 
weight shape for bin/pytorch_weights/layer2_1_conv2_weight.data
128 3 3 128
layer2_1_bn2_running_mean_shape.data num_dims : 1 shape: 128 
layer2_1_bn2_running_var_shape.data num_dims : 1 shape: 128 
layer2_1_bn2_weight_shape.data num_dims : 1 shape: 128 
layer2_1_bn2_bias_shape.data num_dims : 1 shape: 128 
layer2_1_conv3_weight_shape.data num_dims : 4 shape: 512 1 1 128 
weight shape for bin/pytorch_weights/layer2_1_conv3_weight.data
512 1 1 128
layer2_1_bn3_running_mean_shape.data num_dims : 1 shape: 512 
layer2_1_bn3_running_var_shape.data num_dims : 1 shape: 512 
layer2_1_bn3_weight_shape.data num_dims : 1 shape: 512 
layer2_1_bn3_bias_shape.data num_dims : 1 shape: 512 
layer2_2_conv1_weight_shape.data num_dims : 4 shape: 128 1 1 512 
weight shape for bin/pytorch_weights/layer2_2_conv1_weight.data
128 1 1 512
layer2_2_bn1_running_mean_shape.data num_dims : 1 shape: 128 
layer2_2_bn1_running_var_shape.data num_dims : 1 shape: 128 
layer2_2_bn1_weight_shape.data num_dims : 1 shape: 128 
layer2_2_bn1_bias_shape.data num_dims : 1 shape: 128 
layer2_2_conv2_weight_shape.data num_dims : 4 shape: 128 3 3 128 
weight shape for bin/pytorch_weights/layer2_2_conv2_weight.data
128 3 3 128
layer2_2_bn2_running_mean_shape.data num_dims : 1 shape: 128 
layer2_2_bn2_running_var_shape.data num_dims : 1 shape: 128 
layer2_2_bn2_weight_shape.data num_dims : 1 shape: 128 
layer2_2_bn2_bias_shape.data num_dims : 1 shape: 128 
layer2_2_conv3_weight_shape.data num_dims : 4 shape: 512 1 1 128 
weight shape for bin/pytorch_weights/layer2_2_conv3_weight.data
512 1 1 128
layer2_2_bn3_running_mean_shape.data num_dims : 1 shape: 512 
layer2_2_bn3_running_var_shape.data num_dims : 1 shape: 512 
layer2_2_bn3_weight_shape.data num_dims : 1 shape: 512 
layer2_2_bn3_bias_shape.data num_dims : 1 shape: 512 
layer2_3_conv1_weight_shape.data num_dims : 4 shape: 128 1 1 512 
weight shape for bin/pytorch_weights/layer2_3_conv1_weight.data
128 1 1 512
layer2_3_bn1_running_mean_shape.data num_dims : 1 shape: 128 
layer2_3_bn1_running_var_shape.data num_dims : 1 shape: 128 
layer2_3_bn1_weight_shape.data num_dims : 1 shape: 128 
layer2_3_bn1_bias_shape.data num_dims : 1 shape: 128 
layer2_3_conv2_weight_shape.data num_dims : 4 shape: 128 3 3 128 
weight shape for bin/pytorch_weights/layer2_3_conv2_weight.data
128 3 3 128
layer2_3_bn2_running_mean_shape.data num_dims : 1 shape: 128 
layer2_3_bn2_running_var_shape.data num_dims : 1 shape: 128 
layer2_3_bn2_weight_shape.data num_dims : 1 shape: 128 
layer2_3_bn2_bias_shape.data num_dims : 1 shape: 128 
layer2_3_conv3_weight_shape.data num_dims : 4 shape: 512 1 1 128 
weight shape for bin/pytorch_weights/layer2_3_conv3_weight.data
512 1 1 128
layer2_3_bn3_running_mean_shape.data num_dims : 1 shape: 512 
layer2_3_bn3_running_var_shape.data num_dims : 1 shape: 512 
layer2_3_bn3_weight_shape.data num_dims : 1 shape: 512 
layer2_3_bn3_bias_shape.data num_dims : 1 shape: 512 
layer3_0_conv1_weight_shape.data num_dims : 4 shape: 256 1 1 512 
weight shape for bin/pytorch_weights/layer3_0_conv1_weight.data
256 1 1 512
layer3_0_bn1_running_mean_shape.data num_dims : 1 shape: 256 
layer3_0_bn1_running_var_shape.data num_dims : 1 shape: 256 
layer3_0_bn1_weight_shape.data num_dims : 1 shape: 256 
layer3_0_bn1_bias_shape.data num_dims : 1 shape: 256 
layer3_0_conv2_weight_shape.data num_dims : 4 shape: 256 3 3 256 
weight shape for bin/pytorch_weights/layer3_0_conv2_weight.data
256 3 3 256
layer3_0_bn2_running_mean_shape.data num_dims : 1 shape: 256 
layer3_0_bn2_running_var_shape.data num_dims : 1 shape: 256 
layer3_0_bn2_weight_shape.data num_dims : 1 shape: 256 
layer3_0_bn2_bias_shape.data num_dims : 1 shape: 256 
layer3_0_conv3_weight_shape.data num_dims : 4 shape: 1024 1 1 256 
weight shape for bin/pytorch_weights/layer3_0_conv3_weight.data
1024 1 1 256
layer3_0_bn3_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_0_bn3_running_var_shape.data num_dims : 1 shape: 1024 
layer3_0_bn3_weight_shape.data num_dims : 1 shape: 1024 
layer3_0_bn3_bias_shape.data num_dims : 1 shape: 1024 
layer3_1_conv1_weight_shape.data num_dims : 4 shape: 256 1 1 1024 
weight shape for bin/pytorch_weights/layer3_1_conv1_weight.data
256 1 1 1024
layer3_1_bn1_running_mean_shape.data num_dims : 1 shape: 256 
layer3_1_bn1_running_var_shape.data num_dims : 1 shape: 256 
layer3_1_bn1_weight_shape.data num_dims : 1 shape: 256 
layer3_1_bn1_bias_shape.data num_dims : 1 shape: 256 
layer3_1_conv2_weight_shape.data num_dims : 4 shape: 256 3 3 256 
weight shape for bin/pytorch_weights/layer3_1_conv2_weight.data
256 3 3 256
layer3_1_bn2_running_mean_shape.data num_dims : 1 shape: 256 
layer3_1_bn2_running_var_shape.data num_dims : 1 shape: 256 
layer3_1_bn2_weight_shape.data num_dims : 1 shape: 256 
layer3_1_bn2_bias_shape.data num_dims : 1 shape: 256 
layer3_1_conv3_weight_shape.data num_dims : 4 shape: 1024 1 1 256 
weight shape for bin/pytorch_weights/layer3_1_conv3_weight.data
1024 1 1 256
layer3_1_bn3_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_1_bn3_running_var_shape.data num_dims : 1 shape: 1024 
layer3_1_bn3_weight_shape.data num_dims : 1 shape: 1024 
layer3_1_bn3_bias_shape.data num_dims : 1 shape: 1024 
layer3_2_conv1_weight_shape.data num_dims : 4 shape: 256 1 1 1024 
weight shape for bin/pytorch_weights/layer3_2_conv1_weight.data
256 1 1 1024
layer3_2_bn1_running_mean_shape.data num_dims : 1 shape: 256 
layer3_2_bn1_running_var_shape.data num_dims : 1 shape: 256 
layer3_2_bn1_weight_shape.data num_dims : 1 shape: 256 
layer3_2_bn1_bias_shape.data num_dims : 1 shape: 256 
layer3_2_conv2_weight_shape.data num_dims : 4 shape: 256 3 3 256 
weight shape for bin/pytorch_weights/layer3_2_conv2_weight.data
256 3 3 256
layer3_2_bn2_running_mean_shape.data num_dims : 1 shape: 256 
layer3_2_bn2_running_var_shape.data num_dims : 1 shape: 256 
layer3_2_bn2_weight_shape.data num_dims : 1 shape: 256 
layer3_2_bn2_bias_shape.data num_dims : 1 shape: 256 
layer3_2_conv3_weight_shape.data num_dims : 4 shape: 1024 1 1 256 
weight shape for bin/pytorch_weights/layer3_2_conv3_weight.data
1024 1 1 256
layer3_2_bn3_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_2_bn3_running_var_shape.data num_dims : 1 shape: 1024 
layer3_2_bn3_weight_shape.data num_dims : 1 shape: 1024 
layer3_2_bn3_bias_shape.data num_dims : 1 shape: 1024 
layer3_3_conv1_weight_shape.data num_dims : 4 shape: 256 1 1 1024 
weight shape for bin/pytorch_weights/layer3_3_conv1_weight.data
256 1 1 1024
layer3_3_bn1_running_mean_shape.data num_dims : 1 shape: 256 
layer3_3_bn1_running_var_shape.data num_dims : 1 shape: 256 
layer3_3_bn1_weight_shape.data num_dims : 1 shape: 256 
layer3_3_bn1_bias_shape.data num_dims : 1 shape: 256 
layer3_3_conv2_weight_shape.data num_dims : 4 shape: 256 3 3 256 
weight shape for bin/pytorch_weights/layer3_3_conv2_weight.data
256 3 3 256
layer3_3_bn2_running_mean_shape.data num_dims : 1 shape: 256 
layer3_3_bn2_running_var_shape.data num_dims : 1 shape: 256 
layer3_3_bn2_weight_shape.data num_dims : 1 shape: 256 
layer3_3_bn2_bias_shape.data num_dims : 1 shape: 256 
layer3_3_conv3_weight_shape.data num_dims : 4 shape: 1024 1 1 256 
weight shape for bin/pytorch_weights/layer3_3_conv3_weight.data
1024 1 1 256
layer3_3_bn3_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_3_bn3_running_var_shape.data num_dims : 1 shape: 1024 
layer3_3_bn3_weight_shape.data num_dims : 1 shape: 1024 
layer3_3_bn3_bias_shape.data num_dims : 1 shape: 1024 
layer3_4_conv1_weight_shape.data num_dims : 4 shape: 256 1 1 1024 
weight shape for bin/pytorch_weights/layer3_4_conv1_weight.data
256 1 1 1024
layer3_4_bn1_running_mean_shape.data num_dims : 1 shape: 256 
layer3_4_bn1_running_var_shape.data num_dims : 1 shape: 256 
layer3_4_bn1_weight_shape.data num_dims : 1 shape: 256 
layer3_4_bn1_bias_shape.data num_dims : 1 shape: 256 
layer3_4_conv2_weight_shape.data num_dims : 4 shape: 256 3 3 256 
weight shape for bin/pytorch_weights/layer3_4_conv2_weight.data
256 3 3 256
layer3_4_bn2_running_mean_shape.data num_dims : 1 shape: 256 
layer3_4_bn2_running_var_shape.data num_dims : 1 shape: 256 
layer3_4_bn2_weight_shape.data num_dims : 1 shape: 256 
layer3_4_bn2_bias_shape.data num_dims : 1 shape: 256 
layer3_4_conv3_weight_shape.data num_dims : 4 shape: 1024 1 1 256 
weight shape for bin/pytorch_weights/layer3_4_conv3_weight.data
1024 1 1 256
layer3_4_bn3_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_4_bn3_running_var_shape.data num_dims : 1 shape: 1024 
layer3_4_bn3_weight_shape.data num_dims : 1 shape: 1024 
layer3_4_bn3_bias_shape.data num_dims : 1 shape: 1024 
layer3_5_conv1_weight_shape.data num_dims : 4 shape: 256 1 1 1024 
weight shape for bin/pytorch_weights/layer3_5_conv1_weight.data
256 1 1 1024
layer3_5_bn1_running_mean_shape.data num_dims : 1 shape: 256 
layer3_5_bn1_running_var_shape.data num_dims : 1 shape: 256 
layer3_5_bn1_weight_shape.data num_dims : 1 shape: 256 
layer3_5_bn1_bias_shape.data num_dims : 1 shape: 256 
layer3_5_conv2_weight_shape.data num_dims : 4 shape: 256 3 3 256 
weight shape for bin/pytorch_weights/layer3_5_conv2_weight.data
256 3 3 256
layer3_5_bn2_running_mean_shape.data num_dims : 1 shape: 256 
layer3_5_bn2_running_var_shape.data num_dims : 1 shape: 256 
layer3_5_bn2_weight_shape.data num_dims : 1 shape: 256 
layer3_5_bn2_bias_shape.data num_dims : 1 shape: 256 
layer3_5_conv3_weight_shape.data num_dims : 4 shape: 1024 1 1 256 
weight shape for bin/pytorch_weights/layer3_5_conv3_weight.data
1024 1 1 256
layer3_5_bn3_running_mean_shape.data num_dims : 1 shape: 1024 
layer3_5_bn3_running_var_shape.data num_dims : 1 shape: 1024 
layer3_5_bn3_weight_shape.data num_dims : 1 shape: 1024 
layer3_5_bn3_bias_shape.data num_dims : 1 shape: 1024 
layer4_0_conv1_weight_shape.data num_dims : 4 shape: 512 1 1 1024 
weight shape for bin/pytorch_weights/layer4_0_conv1_weight.data
512 1 1 1024
layer4_0_bn1_running_mean_shape.data num_dims : 1 shape: 512 
layer4_0_bn1_running_var_shape.data num_dims : 1 shape: 512 
layer4_0_bn1_weight_shape.data num_dims : 1 shape: 512 
layer4_0_bn1_bias_shape.data num_dims : 1 shape: 512 
layer4_0_conv2_weight_shape.data num_dims : 4 shape: 512 3 3 512 
weight shape for bin/pytorch_weights/layer4_0_conv2_weight.data
512 3 3 512
layer4_0_bn2_running_mean_shape.data num_dims : 1 shape: 512 
layer4_0_bn2_running_var_shape.data num_dims : 1 shape: 512 
layer4_0_bn2_weight_shape.data num_dims : 1 shape: 512 
layer4_0_bn2_bias_shape.data num_dims : 1 shape: 512 
layer4_0_conv3_weight_shape.data num_dims : 4 shape: 2048 1 1 512 
weight shape for bin/pytorch_weights/layer4_0_conv3_weight.data
2048 1 1 512
layer4_0_bn3_running_mean_shape.data num_dims : 1 shape: 2048 
layer4_0_bn3_running_var_shape.data num_dims : 1 shape: 2048 
layer4_0_bn3_weight_shape.data num_dims : 1 shape: 2048 
layer4_0_bn3_bias_shape.data num_dims : 1 shape: 2048 
layer4_1_conv1_weight_shape.data num_dims : 4 shape: 512 1 1 2048 
weight shape for bin/pytorch_weights/layer4_1_conv1_weight.data
512 1 1 2048
layer4_1_bn1_running_mean_shape.data num_dims : 1 shape: 512 
layer4_1_bn1_running_var_shape.data num_dims : 1 shape: 512 
layer4_1_bn1_weight_shape.data num_dims : 1 shape: 512 
layer4_1_bn1_bias_shape.data num_dims : 1 shape: 512 
layer4_1_conv2_weight_shape.data num_dims : 4 shape: 512 3 3 512 
weight shape for bin/pytorch_weights/layer4_1_conv2_weight.data
512 3 3 512
layer4_1_bn2_running_mean_shape.data num_dims : 1 shape: 512 
layer4_1_bn2_running_var_shape.data num_dims : 1 shape: 512 
layer4_1_bn2_weight_shape.data num_dims : 1 shape: 512 
layer4_1_bn2_bias_shape.data num_dims : 1 shape: 512 
layer4_1_conv3_weight_shape.data num_dims : 4 shape: 2048 1 1 512 
weight shape for bin/pytorch_weights/layer4_1_conv3_weight.data
2048 1 1 512
layer4_1_bn3_running_mean_shape.data num_dims : 1 shape: 2048 
layer4_1_bn3_running_var_shape.data num_dims : 1 shape: 2048 
layer4_1_bn3_weight_shape.data num_dims : 1 shape: 2048 
layer4_1_bn3_bias_shape.data num_dims : 1 shape: 2048 
layer4_2_conv1_weight_shape.data num_dims : 4 shape: 512 1 1 2048 
weight shape for bin/pytorch_weights/layer4_2_conv1_weight.data
512 1 1 2048
layer4_2_bn1_running_mean_shape.data num_dims : 1 shape: 512 
layer4_2_bn1_running_var_shape.data num_dims : 1 shape: 512 
layer4_2_bn1_weight_shape.data num_dims : 1 shape: 512 
layer4_2_bn1_bias_shape.data num_dims : 1 shape: 512 
layer4_2_conv2_weight_shape.data num_dims : 4 shape: 512 3 3 512 
weight shape for bin/pytorch_weights/layer4_2_conv2_weight.data
512 3 3 512
layer4_2_bn2_running_mean_shape.data num_dims : 1 shape: 512 
layer4_2_bn2_running_var_shape.data num_dims : 1 shape: 512 
layer4_2_bn2_weight_shape.data num_dims : 1 shape: 512 
layer4_2_bn2_bias_shape.data num_dims : 1 shape: 512 
layer4_2_conv3_weight_shape.data num_dims : 4 shape: 2048 1 1 512 
weight shape for bin/pytorch_weights/layer4_2_conv3_weight.data
2048 1 1 512
layer4_2_bn3_running_mean_shape.data num_dims : 1 shape: 2048 
layer4_2_bn3_running_var_shape.data num_dims : 1 shape: 2048 
layer4_2_bn3_weight_shape.data num_dims : 1 shape: 2048 
layer4_2_bn3_bias_shape.data num_dims : 1 shape: 2048 
fc_weight_shape.data num_dims : 2 shape: 1000 2048 
fc_bias_shape.data num_dims : 1 shape: 1000 
Auto-scheduled time: 25.0737ms
 class: 836
make: Leaving directory '/home/ubuntu/llvm-project/Halide/apps/resnet_50_blockwise'


RL_END_OF_RUN 3

